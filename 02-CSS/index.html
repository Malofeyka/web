<!DOCTYPE html>

<html lang="ru" xmlns="http://www.w3.org/1999/xhtml">
<head>
    <meta charset="utf-8" />
    <title>CSS</title>
    <!--<link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Playwrite+CU:wght@100..400&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel="stylesheet">-->
    <link rel="stylesheet" href="style1.css" />

</head>
<body>
    <h1>
        Современные десктопные процессоры архитектуры x86
    </h1>

    <p id="Intro">
        общие принципы работы (x86 CPU digest 2.0) <br> <br>
        Этот материал представляет собой обновлённую, существенно переработанную и дополненную версию статьи 2006 года, которая называлась «Современные десктопные процессоры архитектуры x86: общие принципы работы (<b>x86 CPU FAQ 1.0</b>)». Правда, чтобы не вводить потенциальных читателей в заблуждение словом «FAQ», мы решили назвать новый материал более правильным, как нам кажется, термином — «дайджест». Действительно, ведь большая его часть — это не ответы на конкретные вопросы, а разъяснения и краткие выжимки из чего угодно — от технической документации до истории развития микропроцессорной отрасли. Для кого предназначен данный материал? Нам видятся две группы потенциальных читателей.
    <p />

    <p><span class="Definition">Первая</span> — это те, кто вдруг обнаружил, что ему действительно интересно узнать, как работает современный x86-процессор. Для них мы попытались сосредоточить в рамках статьи максимальное количество полезных сведений, которые позволяют получить более-менее полное представление об этом процессе, даже не имея до этого (почти) никаких специальных знаний: здесь объясняется значение основных терминов, устройство современных CPU, принципы взаимодействия различных их составляющих между собой, а также процессора с компьютерной системой в целом.</p>

    <p><span class="Definition">Вторая группа </span>— это те, кто не найдёт в статье почти ничего нового для себя — но им попросту лень писать нечто похожее самостоятельно, чтобы сосредоточить разбросанные по мозгу знания в одном месте, «причесать» их, систематизировать, упорядочить, осовременить, и так далее. Мы сами отлично понимаем, как бывает лениво писать конспекты :) (а особенно — хорошие конспекты), поэтому если наш дайджест вас устраивает — мы с радостью дарим вам возможность им пользоваться.</p>

    <p>Ну и традиционное предупреждение: если иное не указано явно, то слово «процессор» в данном материале обозначает «<b>x86(-64) процессор</b>, предназначенный для установки в десктопы или (намного реже) мобильные компьютеры». Серверные процессоры, специализированные процессоры с архитектурой x86, всевозможные embedded-варианты — всё это в рамках статьи не рассматривается.Оглавление</p>

    <h2>Общее устройство вычислительной машины</h2>

    <p>Любой компьютер как универсальный инструмент для работы с информацией устроен очень просто. Все его части можно разделить на 3 вида: устройства обработки, хранения и обмена (ввода-вывода), причём последние могут осуществлять обмен данными как между компьютером и человеком, так и между другими компьютерами. С информационной точки зрения больше ничего там нет, хотя учитывая, что компьютер — устройство электрическое, ему нужен источник питания, кабели и т.п., но это общая часть всей электроники. При этом каждый элемент сам делится на компоненты вышеперечисленных трёх видов. Например, процессор относится к устройствам обработки, но внутри себя имеет блоки собственно вычислений, локальной памяти и обмена. Большая часть пока ещё непонятных терминов именует конкретные детали процессора или методы их взаимодействий.</p>
    <h3>Код и данные: основной принцип работы процессора</h3>
    <p>
        Если не пытаться изложить здесь «кратенько» курс информатики для средней школы, то единственное что хотелось бы напомнить — это то, что процессор (за редкими исключениями) исполняет не программы, написанные на каком-нибудь языке программирования (один из которых, вы, возможно, даже знаете), а так называемый машинный код. Т.е. командами для него являются последовательности байтов, находящихся в памяти компьютера, не имеющие ничего общего не только с каким-то человеческим языком, но и с языком программирования высокого уровня. Каждая команда занимает до нескольких байт, в среднем — 3-5. Там же, в основной памяти (ОЗУ, RAM) находятся и данные. Они могут находиться в отдельной области, а могут и быть перемешаны с кодом. Различие между кодом и данными состоит в том, что данные — это то, над чем процессор производит операции. А код — это команды, которые ему сообщают, какую именно операцию он должен произвести. Одновременно в памяти располагаются множество программ, необходимых им данных и некоторое свободное место.
    </p>
    <figure>
        <img src="https://i.imgur.com/hcsdvLw.png" alt="VonNeumann" />
        <figcaption>
            Блок-схема «<a href="https://ru.wikipedia.org/wiki/%D0%90%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D0%B0_%D1%84%D0%BE%D0%BD_%D0%9D%D0%B5%D0%B9%D0%BC%D0%B0%D0%BD%D0%B0?utm_source=ixbtcom">машины фон Неймана</a>», <br>
            на принципах которой построены все x86-процессоры
        </figcaption>
    </figure>
    <p>
        Чтобы исполнить команду, процессор должен прочитать её из памяти. Чтобы произвести операцию над данными (а этого требует почти каждая команда), процессор должен прочитать их из памяти, и, возможно, после произведения над ними определённого действия, записать их обратно в память в обновлённом (изменённом) виде. Команды и данные идентифицируются их адресом, который представляет собой порядковый номер байта в памяти, с которого эти данные начинаются (если они занимают несколько байт). Общие принципы взаимодействия процессора и ОЗУ
        <br>
        <br>
        Возможно, кого-то удивит, что достаточно большой раздел в «Дайджесте», посвящённом x86 CPU, выделен под объяснение особенностей функционирования памяти в современных системах, основанных на данном типе процессоров. Однако факты — упрямая вещь: сами x86-процессоры ныне содержат так много блоков, отвечающих именно за оптимизацию их работы с ОЗУ, что игнорировать эту тесную связь было бы совершенно нелепо. Можно сказать даже так: уж, коль решения, связанные с оптимизацией работы с памятью, стали неотъемлемой частью самих процессоров — то и саму память можно рассматривать в качестве некоего «придатка», функционирование которого оказывает непосредственное влияние на скорость работы CPU. Без понимания особенностей взаимодействия процессора с памятью, невозможно понять, за счёт чего тот или иной процессор (та или иная система) исполняет программы медленнее или быстрее.
    </p>

    <h3>
        Контроллер памяти
    </h3>

    <p>
        Итак, ранее выше мы уже говорили о том, что как команды, так и данные, попадают в процессор из оперативной памяти. На самом деле всё немного сложнее. Ещё недавно в большинстве x86-систем (т.е. компьютеров на базе x86-процессоров), процессор к памяти обращаться сам не мог, т.к. не имел в своём составе соответствующих узлов. Некоторые не самые новые, но ещё популярные линейки процессоров (Intel Core 2, Celeron и Pentium всех видов) используют такую классическую организацию и сейчас. В этой схеме процессор обращается к «промежуточному» специализированному устройству, называемому контроллером памяти, а уже тот, в свою очередь — к микросхемам ОЗУ, размещенным на модулях памяти. Модули вы наверняка видели — это такие длинные узкие текстолитовые «планочки» (фактически — небольшие платы) с несколькими микросхемами на них, вставляемые в специальные разъёмы на системной плате. Роль контроллера ОЗУ, таким образом, проста: он служит своего рода «мостом» между памятью и использующими её устройствами (а это не только процессор, но об этом — чуть позже).
    </p>
    <figure>
        <img src="https://i.imgur.com/lozmMXa.png" alt="Scheme" />
        <figcaption>
            Блок-схема x86-система с внешним контроллером памяти (слева) <br>
            и с контроллером памяти, встроенным в процессор (справа)», <br>
            на принципах которой построены все x86-процессоры
        </figcaption>
    </figure>
    <p>
        В традиционной схеме, контроллер памяти входит в состав чипсета — набора микросхем, являющегося основой системной платы. От быстродействия контроллера во многом зависит скорость обмена данными между процессором и памятью, это один из важнейших компонентов, влияющих на общую производительность компьютера. По «новой» схеме (к ней относятся процессоры Intel Core с буквой «i», и все ныне выпускаемые CPU AMD), контроллер памяти входит в состав самого процессора — теперь никаких посредников между памятью и процессором нет, так что общаться им оказывается проще и быстрее. Однако многочисленным устройствам ввода-вывода жизнь несколько усложнилась — им путь до памяти стал на один шаг длиннее, т.к. чипсет никуда не исчез (а лишь лишился контроллера памяти), и теперь обращаться к памяти требуется через процессор, отвлекая его от выполнения программ. Тем не менее, новая схема является прогрессивной, потому что процессору важнее всего получить доступ к памяти как можно быстрее, даже ценой некоторого усложнения доступа для других устройств — именно он является главным потребителем и производителем той информации, которая записана в памяти.
    </p>
    <h3>Процессорная шина</h3>
    <p>
        Любой процессор обязательно оснащён как минимум одной процессорной шиной, которую в среде x86 CPU иногда по старинке называют FSB (Front Side Bus), хотя современные процессоры имеют для неё разные названия (QPI для Intel и HyperTransport для AMD). В многопроцессорных платах таких шин несколько, и связаны они с другими процессорами и чипсетом. В домашних компьютерах, где процессор, как правило, один, шина у него единственная (не считая шины памяти, если в процессор встроен её контроллер) и связывает его с чипсетом, а через него — со всеми остальными устройствами.
    </p>
    <h2>Оперативная память</h2>
    <h3>Разрядность шины памяти, N-канальные контроллеры памяти</h3>
    <p>
        На сегодняшний день вся память, используемая в современных десктопных x86-системах, имеет шину шириной 64 бита. Это означает, что за один такт по данной шине одновременно может быть передано количество информации, кратное 8 байтам (8 байт для SDR-шин, 16 байт для DDR-шин). Особняком стоит только память типа RDRAM, применявшаяся в системах на базе процессоров Intel Pentium 4 на заре становления архитектуры NetBurst, но сейчас это направление признано тупиковым для x86-ПК (к слову — руку к этому приложила всё та же компания Intel, которая в своё время активно пропагандировала данный тип памяти). Некоторую неразбериху вносят лишь многоканальные контроллеры, обеспечивающие одновременную работу с несколькими отдельными друг от друга 64-битными шинами. Применительно к 2-канальным котроллерам некоторые производители заявляют о «128-битности». Однако арифметика на уровне 1-го класса в данном случае работает с оговоркой: 2x64 равно 128 только когда все каналы работают одновременно. Т.е. N-канальный контроллер памяти теоретически может увеличить скорость работы с данными в N раз, но при этом ширина каждой шины памяти во всех современных контроллерах, применяемых в x86-системах по-прежнему равна 64 битам. На данный момент времени, одноканальный контроллер памяти можно смело назвать анахронизмом: все современные x86-системы оснащены как минимум 2-канальными контроллерами памяти, а некоторые — даже 3-канальными.
    </p>
    <h3>
        Скорость чтения и записи
    </h3>
    <p>
        Скорость чтения и записи информации в память теоретически ограничивается исключительно пропускной способностью самой памяти. Так, например, двухканальный контроллер памяти стандарта DDR2-800 теоретически способен обеспечить скорость чтения и записи информации, равную 8 байт (ширина шины) * 2 (количество каналов) * 2 (протокол DDR, обеспечивающий передачу 2 пакетов данных за 1 такт) * 400'000'000 (фактическая частота работы шины памяти равная 400 МГц, т.е. 400 млн. тактов в секунду). Упомянем, что полученное произведение измеряется не в МБ/с (ГБ/с), а млн. (млрд.) байт/с, что несколько меньше честных двоичных «мега-» и «гига-». Даже с учётом этого, значения, получаемые в результате практических тестов, как правило, чуть ниже теоретических: сказывается «неидеальность» конструкции контроллера памяти, плюс накладки (задержки), вызванные работой подсистемы кэширования самого процессора (см. ниже раздел про процессорный кэш). Однако основной «подвох» содержится даже не в накладках, а в том, что скорость «линейного» чтения или записи является вовсе не единственной характеристикой, влияющей на фактическую скорость работы процессора с ОЗУ. Необходимо кроме линейной скорости считывания или записи учитывать ещё и такую характеристику, как латентность.
    </p>
    <h3>Латентность</h3>
    <p>
        Латентность (она же — задержка) является не менее важной характеристикой с точки зрения быстродействия подсистемы памяти, чем скорость «прокачки данных». Большая скорость обмена данными хороша тогда, когда их размер относительно велик, но если нам требуется «понемногу с разных адресов» — то на первый план выходит именно латентность. Что это такое? В общем случае — время, которое требуется для того, чтобы начать считывать информацию с определённого адреса. И действительно: с момента, когда процессор посылает контроллеру памяти команду на считывание (запись), и до момента, когда эта операция осуществляется, проходит определённое время. Причём оно вовсе не равно времени, которое требуется на пересылку данных. Приняв команду на чтение или запись от процессора, контроллер памяти «указывает» ей, с каким адресом он желает работать. Доступ к любому произвольно взятому адресу не может быть осуществлён мгновенно. Возникает задержка: адрес указан, но память не готова предоставить к нему доступ, особенно если он указывает на слишком далёкое от предыдущей операции место (по разнице адресов). В общем случае, эту задержку и принято называть латентностью. У разных типов памяти она разная. Так, например, память типа DDR3 имеет в среднем большие задержки, чем DDR2 (при одинаковой частоте передачи данных). В результате, если данные в программе расположены «хаотично» и «небольшими кусками», либо метод считывания или записи совсем не последовательный, то скорость обмена становится намного менее важной, чем скорость доступа к «началу куска», т.к. задержки при переходе на очередной адрес влияют на быстродействие системы намного сильнее, чем скорость считывания или записи.
        <br>
        <br>
        «Соревнование» между скоростью чтения (записи) и латентностью — одна из основных головных болей разработчиков современных систем: к сожалению, рост скорости чтения (записи) почти всегда приводит к увеличению латентности. Так, например, память типа DDR обладает в среднем лучшей (меньшей) латентностью, чем DDR2. В свою очередь, у DDR3 латентность ещё выше (то есть хуже), чем у DDR2. Правда, здесь следует хорошо понимать, каким образом следует правильно сравнивать латентность. Если вы интересовались данным вопросом, вам наверняка хорошо знакома строчка вида «4-4-4-12», обозначающая как раз величину задержек при выполнении некоторых операций. Задержки в данном случае указаны в тактах частоты, на которой работает память. В то же время, если нас интересует латентность как единица измерения скорости, то считать её нужно не в тактах, а в секундах. Именно на этом часто «прокалываются» не очень хорошо разбирающиеся в вопросе пользователи, не понимающие, почему латентность, к примеру, в 6 тактов, может быть меньше, чем латентность в 4 такта. А всё очень просто: например, если модуль памяти с латентностью в 6 тактов, работает на частоте 800 МГц, а модуль памяти с латентностью 4 — на частоте 400 МГц — то совершенно очевидно, что 6 тактов на частоте 800 МГц займут меньше времени, чем 4 на частоте 400.
        <br>
        <br>
        Также следует понимать, что «общая» латентность подсистемы памяти зависит не только от неё самой, но и от контроллера памяти и места его расположения — все эти факторы тоже влияют на задержку. Именно поэтому компания AMD в процессе разработки архитектуры AMD64 решила «одним махом» решить проблему высокой латентности, интегрировав контроллер прямо в процессор — чтобы максимально «сократить дистанцию» между процессорным ядром и модулями ОЗУ. Затея удалась, но с подвохом: теперь система на базе процессора AMD может работать только с той памятью, на которую рассчитан контроллер процессора. Наверное, поэтому компания Intel долго не решалась на такой кардинальный шаг, предпочитая действовать традиционными методами: усовершенствуя контроллер памяти в чипсете и механизм предзагрузки в процессоре (про него см. ниже) — пока всё-таки не согласилась, что идея AMD выгодней.
        <br>
        <br>
        В завершение заметим, что понятия «скорость чтения / записи» и «латентность», в общем случае, применимы к любому типу памяти — в том числе не только к классическому ОЗУ (SDR, Rambus, DDR, DDR2, DDR3, …), но и к кэшу (см. ниже). Процессор: сведения общего характера
    </p>

    <h2>Понятие архитектуры</h2>
    <h3>Архитектура как совместимость с кодом</h3>
    <p>
        Наверняка вы часто встречались с термином «x86», или «Intel-совместимый процессор» (или «IBM PC compatible» — но это уже по отношению к компьютеру). Иногда также встречается термин «Pentium-совместимый» (почему именно Pentium — вы поймете сами чуть позже). Что скрывается за всеми этими названиями? На данный момент наиболее корректно с точки зрения авторов выглядит следующая простая формулировка: современный x86-процессор — это процессор, способный корректно исполнять машинный код архитектуры x86-64 (архитектура 32-битных процессоров Intel, дополненная 64-битными расширениями от AMD). В первом приближении современный x86 — это код, исполняемый процессором i80386 (известным в народе как «386-й»), окончательно же основной набор команд 32-битной архитектуры IA32 сформировался с выходом процессора Intel Pentium Pro (с очень незначительным дополнениями в следующих процессорах). Что означает «основной набор» и какие есть еще? Для начала ответим на первую часть. «Основной» в данном случае означает то, что с помощью исключительно этого набора команд может быть написана любая программа для процессора архитектуры x86.
        <br>
        <br>
        Кроме того, у архитектуры IA32 существуют «официальные» расширения (дополнительные наборы команд) от разработчика самой архитектуры, компании Intel: MMX, многочисленные SSE (вплоть до 4.2) и AVX. Также существуют «неофициальные» (не от Intel) расширенные наборы команд: EMMX, 3DNow!, Extended 3DNow!, SSE4.a и XOP — их разработала компания AMD. Впрочем, «официальность» и «неофициальность» в данном случае понятие относительное — де-факто всё сводится к тому, что некоторые расширения набора команд Intel как разработчик изначального набора признаёт, а некоторые — нет, разработчики же программного обеспечения используют то, что им лучше всего подходит. В отношении расширенных наборов команд существует правило хорошего тона: прежде чем их использовать, программа должна проверить, поддерживает ли их процессор. Иногда отступления от этого правила встречаются (и могут приводить к неправильному функционированию программ), но объективно это является проблемой некорректно написанной программы, а не процессора.
        <br>
        <br>
        Для чего предназначены дополнительные наборы команд? В первую очередь — для увеличения быстродействия при выполнении наиболее частых операций. Одна команда из дополнительного набора, как правило, выполняет действие, для которого понадобилась бы небольшая процедура, состоящая из команд основного набора, причём специальная команда выполняется процессором быстрее, чем заменяющая её последовательность. Однако в 99% случаев ничего такого, чего нельзя было бы сделать с помощью основных команд, команды из дополнительного набора также не делают. Таким образом, упомянутая выше программная проверка поддержки дополнительных наборов команд процессором должна выполнять очень простую функцию: если, например, процессор поддерживает SSE — значит, считать будем быстро и с помощью команд из набора SSE. Если нет — будем считать медленнее, с помощью команд из основного набора. Корректно написанная программа обязана действовать именно так. Впрочем, сейчас практически никто не проверяет у процессора наличие поддержки MMX, т.к. все CPU, вышедшие за последние 10 лет, этот набор поддерживают гарантированно. Для справки приведём табличку, на которой обобщена информация о поддержке различных расширенных наборов команд различными десктопными (предназначенными для настольных ПК) и некоторыми мобильными процессорами.
    </p>
    <table><tbody><tr class="thead"><td>Процессор</td><td>Год выпуска</td><td>x86-64</td><td>PPro</td><td>MMX</td><td>Версия<br>SSE</td><td>3DNow!</td></tr><tr class="thead"><td colspan="7"><em>Процессоры Intel</em></td></tr><tr class="row1"><td>Pentium</td><td>1993</td><td></td><td></td><td></td><td></td><td></td></tr><tr class="row2"><td>Pentium Pro</td><td>1995</td><td></td><td>x</td><td></td><td></td><td></td></tr><tr class="row1"><td>Pentium MMX</td><td rowspan="2">1997</td><td></td><td></td><td>x</td><td></td><td></td></tr><tr class="row2"><td>Pentium II</td><td></td><td>x</td><td>x</td><td></td><td></td></tr><tr class="row1"><td>Celeron</td><td>1998</td><td></td><td>x</td><td>x</td><td></td><td></td></tr><tr class="row2"><td>Pentium III</td><td>1999</td><td></td><td>x</td><td>x</td><td>1</td><td></td></tr><tr class="row1"><td>Pentium 4</td><td rowspan="2">2000</td><td></td><td>x</td><td>x</td><td>2</td><td></td></tr><tr class="row2"><td>Celeron</td><td></td><td>x</td><td>x</td><td>1</td><td></td></tr><tr class="row1"><td>Celeron</td><td>2002</td><td></td><td>x</td><td>x</td><td>2</td><td></td></tr><tr class="row2"><td>Pentium M</td><td>2003</td><td></td><td>x</td><td>x</td><td>2</td><td></td></tr><tr class="row1"><td>Pentium 4</td><td rowspan="2">2004</td><td>x</td><td>x</td><td>x</td><td>3</td><td></td></tr><tr class="row2"><td>Celeron D</td><td></td><td>x</td><td>x</td><td>3</td><td></td></tr><tr class="row1"><td>Pentium D, EE</td><td rowspan="2">2005</td><td rowspan="2">x</td><td rowspan="2">x</td><td rowspan="2">x</td><td rowspan="2">3</td><td></td></tr><tr class="row2"><td>Celeron D</td><td></td></tr><tr class="row1"><td>Celeron</td><td rowspan="4">2006</td><td>x</td><td>x</td><td>x</td><td>3S</td><td></td></tr><tr class="row2"><td>Celeron M</td><td rowspan="2"></td><td rowspan="2">x</td><td rowspan="2">x</td><td rowspan="2">3</td><td></td></tr><tr class="row1"><td>Core Solo, Duo</td><td></td></tr><tr class="row2"><td>Core 2</td><td>x</td><td>x</td><td>x</td><td>3S</td><td></td></tr><tr class="row1"><td>Core 2</td><td rowspan="4">2007</td><td>x</td><td>x</td><td>x</td><td>4.1</td><td></td></tr><tr class="row2"><td>Celeron M</td><td rowspan="2">x</td><td rowspan="2">x</td><td rowspan="2">x</td><td rowspan="2">3S</td><td></td></tr><tr class="row1"><td>Pentium (DC)</td><td></td></tr><tr class="row2"><td>Pentium (DC, M)</td><td></td><td>x</td><td>x</td><td>3</td><td></td></tr><tr class="row1"><td>Atom</td><td rowspan="3">2008</td><td rowspan="2">x</td><td rowspan="2">x</td><td rowspan="2">x</td><td rowspan="2">3S</td><td></td></tr><tr class="row2"><td>Celeron (DC)</td><td></td></tr><tr class="row1"><td>Core i7</td><td>x</td><td>x</td><td>x</td><td>4.2</td><td></td></tr><tr class="row2"><td>Core i3, i5</td><td>2009</td><td>x</td><td>x</td><td>x</td><td>4.2</td><td></td></tr><tr class="row1"><td>Core i9</td><td>2010</td><td>x</td><td>x</td><td>x</td><td>4.2</td><td></td></tr><tr class="thead"><td colspan="7"><em>Процессоры AMD</em></td></tr><tr class="row1"><td>K5</td><td>1996</td><td></td><td></td><td></td><td></td><td></td></tr><tr class="row2"><td>K6</td><td>1997</td><td></td><td></td><td>x</td><td></td><td></td></tr><tr class="row1"><td>K6-3D, K6-2+</td><td>1998</td><td></td><td></td><td>x</td><td></td><td>x</td></tr><tr class="row2"><td>K6-III</td><td rowspan="2">1999</td><td></td><td></td><td>x</td><td></td><td>x</td></tr><tr class="row1"><td>Athlon</td><td></td><td>x</td><td>x</td><td></td><td>x</td></tr><tr class="row2"><td>Duron</td><td>2000</td><td></td><td>x</td><td>x</td><td></td><td>x</td></tr><tr class="row1"><td>Athlon XP</td><td rowspan="3">2001</td><td rowspan="3"></td><td rowspan="3">x</td><td rowspan="3">x</td><td rowspan="3">1</td><td rowspan="3">x</td></tr><tr class="row2"><td>Athlon 4 (M)</td></tr><tr class="row1"><td>Duron</td></tr><tr class="row2"><td>Athlon 64</td><td>2003</td><td>x</td><td>x</td><td>x</td><td>2</td><td>x</td></tr><tr class="row1"><td>Sempron</td><td>2004</td><td></td><td>x</td><td>x</td><td>1 (2)</td><td>x</td></tr><tr class="row2"><td>Athlon XP-M</td><td rowspan="5">2005</td><td></td><td>x</td><td>x</td><td>2</td><td>x</td></tr><tr class="row1"><td>Sempron</td><td>x</td><td>x</td><td>x</td><td>2 (3)</td><td>x</td></tr><tr class="row2"><td>Athlon (64) X2</td><td rowspan="2">x</td><td rowspan="2">x</td><td rowspan="2">x</td><td rowspan="2">3</td><td rowspan="2">x</td></tr><tr class="row1"><td>Turion (M)</td></tr><tr class="row2"><td>Sempron (M)</td><td></td><td>x</td><td>x</td><td>3</td><td>x</td></tr><tr class="row1"><td>Phenom</td><td>2007</td><td>x</td><td>x</td><td>x</td><td>4.a</td><td>x</td></tr><tr class="row2"><td>Athlon X2</td><td>2008</td><td>x</td><td>x</td><td>x</td><td>4.a</td><td>x</td></tr><tr class="row1"><td>Athlon Neo</td><td rowspan="3">2009</td><td>x</td><td>x</td><td>x</td><td>3</td><td>x</td></tr><tr class="row2"><td>Phenom II</td><td rowspan="2">x</td><td rowspan="2">x</td><td rowspan="2">x</td><td rowspan="2">4.a</td><td rowspan="2">x</td></tr><tr class="row1"><td>Athlon II, X3, X4</td></tr></tbody></table>
    <p>
        Примечания:<br>
        PPro — означает наличие всех общих команд;<br>
        Версия SSE — номер последней поддерживаемой версии, подразумевая и все предыдущие;<br>
        Ряд SSE: SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2;<br>
        Для процессоров AMD наличие SSE4.a означает поддержку только SSE, SSE2, SSE3 и SSE4.a;<br>
        (M) — мобильная модель, даже если явно в имени не указано;<br>
        (DC) — двухядерный процессор, указано в индексе модели.<br>
        <br>
        На данный момент всё популярное десктопное программное обеспечение (операционные системы Windows и Linux, офисные пакеты, компьютерные игры, и прочее) разрабатывается именно для x86-процессоров. Оно выполняется (за исключением «дурно воспитанных» программ) на любом x86-процессоре, независимо от того, кто его произвёл. Поэтому вместо ориентированных на разработчика изначальной архитектуры терминов «Intel-совместимый» или «Pentium-совместимый», стали употреблять нейтральное название: «x86-совместимый процессор», «процессор с архитектурой x86». В данном случае под «архитектурой» понимается архитектура системы команд (ISA, <a href="https://en.wikipedia.org/wiki/Instruction_set?utm_source=ixbtcom">Instruction Set Architecture</a>) — совместимость с определённым набором команд с точки зрения программиста. Есть и другая трактовка того же термина.
    </p>
    <h3>Архитектура как характеристика семейства процессоров</h3>
    «Железячники» — люди, работающие в основном не с программным обеспечением, а с аппаратным — под «архитектурой» понимают несколько другое (правда, более корректно то, что они называют «архитектурой», называется «микроархитектурой», но приставку «микро» частенько опускают). Для них «архитектура CPU» — это некий набор свойств, присущий целому семейству процессоров, как правило, выпускаемому в течение многих лет (иначе говоря — их организация и «внутренняя конструкция»). Например, любой специалист по x86 CPU вам скажет, что процессор с ALU, работающими на удвоенной частоте, QDR-шиной, Trace cache, и, возможно, поддержкой технологии Hyper-Threading — это «процессор архитектуры NetBurst» (не пугайтесь незнакомых терминов — все нужные будут разъяснены чуть позже). Таким образом, понятие «архитектуры» применительно к процессорам двойственно: под ним может пониматься как совместимость с единым набором команд, так и совокупность аппаратных решений, присущих определённой достаточно широкой группе процессоров.

    <h3>64-битные расширения классической x86 (IA32) архитектуры</h3>
    <p>
        В 2003 г. сначала AMD, а через год — и Intel, анонсировали практически идентичные технологии (впрочем, AMD предпочитает называть это архитектурой), благодаря которым классические x86 (IA32) CPU получили статус 64-битных. В случае с AMD данная технология получила наименование «AMD64», в случае с Intel — сначала «EM64T», а теперь Intel 64. Впрочем, сегодня часто указывают нейтральное «x86-64» — как общее обозначение всех 64-битных расширений архитектуры x86, не привязанное к зарегистрированным торговым маркам. Употребление одного из трёх приведённых наименований зависит больше от личных предпочтений употребляющего, чем от фактических различий — ибо различия между AMD64 и EM64T умещаются на кончике очень тонкой иглы. Так или иначе, всё сводится к следующему: все целочисленные регистры (общего назначения) стали вместо 32-битных 64-битными, число регистров (и общих, и векторных) удвоилось, 32-битные команды x86-кода получили свои 64-битные аналоги, а объём адресуемой памяти (и физической, и виртуальной) многократно увеличился (за счёт того, что логический адрес приобрёл вместо 32-битного 64-битный формат). Количество маркетинговых спекуляций на тему «64-битности» превысило все разумные пределы, поэтому следует рассмотреть достоинства данного нововведения. <br><br>

        Что не изменилось? В первую очередь — быстродействие процессоров. Вопиющей глупостью будет считать, что один и тот же процессор при переходе из привычного 32-битного в 64-битный режим (а 32-битный режим все нынешние x86 CPU поддерживают в обязательном порядке) станет работать вдвое быстрее. Разумеется, в некоторых случаях ускорение от использования 64-битной целочисленной арифметики может присутствовать — но количество этих случаев сильно ограничено, и большинства современного пользовательского программного обеспечения они никак не касаются. Кстати: а почему мы употребили термин «64-битная целочисленная арифметика»? А потому, что блоки операций с плавающей точкой (см. ниже) во всех x86-процессорах уже давным-давно не 32-битные. И даже не 64-битные. Классический вещественный вычислитель, окончательно ставший частью CPU ещё во времена старого доброго 32-битного Intel Pentium* — уже был 80-битным (и до сих пор таков). Векторные операнды команд SSE (с любой цифрой) — и вовсе 128-битные! В этом плане архитектура x86 достаточно парадоксальна: притом, что формально процессоры данной архитектуры достаточно долгое время оставались 32-битными — разрядность тех блоков, где «большая битность» была реально необходима — наращивалась совершенно независимо от остальных (<a href="https://www.ixbt.com/cpu/cpu-bitness.shtml">более подробно о проблеме разрядности процессоров можно почитать в отдельном материале</a>). Например, процессоры AMD Athlon XP и Intel Pentium 4 «Northwood» совмещали в себе блоки, работающие с 32-битными, 80-битными, и 128-битными операндами. 32-битными оставались лишь основной набор команд (унаследованный от первого процессора архитектуры IA32 — Intel 386) и адресация памяти (максимум 4 гигабайта, если не считать «эквилибристического выверта» от Intel — <a href="https://ru.wikipedia.org/wiki/PAE">Physical Address Extension</a>, позволявшего «32-битным» процессорам использовать 36(!)-битную адресацию).
    </p>
    <blockquote>* &mdash; первым x86 CPU, в который был интегрирован FPU (ранее он устанавливался на плату в качестве отдельного чипа), стал процессор предыдущего поколения — i486DX. Но в линейке i486 всё-таки присутствовал i486SX, в состав которого FPU не входил. Начиная с Pentium, Intel больше не выпускала x86 CPU без FPU, и эту моду быстро подхватили все остальные производители.</blockquote>
    <p>Таким образом, то, что процессоры AMD и Intel стали «формально 64-битными», на практике принесло нам лишь три усовершенствования: появление команд для работы с 64-битными целыми числами, увеличение количества и/или разрядности регистров, и увеличение максимального объёма адресуемой памяти. Заметим: реальной пользы этих нововведений (особенно третьего!) никто не отрицает. Равно как никто не отрицает заслуг компании AMD в продвижении идеи «осовременивания» (за счёт введения 64-битности) x86-процессоров. Мы лишь хотим предостеречь от чрезмерных ожиданий: не стоит надеяться на то, что компьютер, покупавшийся «в ценовом классе ВАЗа», от установки 64-битного программного обеспечения станет «лихим Мерседесом». Чудес на свете не бывает...</p>
    <h2>Процессорное ядро</h2>
    <h3>О многоядерности (многопроцессорности) как концепции</h3>
    <figure>
        <img src="https://i.imgur.com/ZArDLDa.png" alt="Scheme" />
        <figcaption>
            Классическая одноядерная (однопроцессорная) схема: в памяти находится код нескольких программ <br>
            («кирпичики» разного цвета), но в один момент времени процессор выполняет код только одной из<br> них
        </figcaption>
    </figure>
    <p>
        Прежде, чем мы начнём описывать особенности многоядерных систем, нужно вначале объяснить, зачем вообще они нужны, и как за счёт большего количества ядер и/или процессоров может достигаться  положительный эффект. В данном случае мы для простоты считаем, что система, собранная на базе одного процессора с двумя ядрами, практически идентична по функционалу системе на базе двух процессоров с одним ядром — если ядра в обоих случаях идентичны*. Более подробное разъяснение можно прочитать в отдельном, более сложном материале, но хотя бы схематически описать ситуацию просто необходимо. Всё нижесказанное относится к концепции SMP (<a href="https://en.wikipedia.org/wiki/Symmetric_multiprocessing">Symmetric Multiprocessing</a>, cимметричная многопроцессорность), т.к. пока на x86 прижился именно этот вариант. Он требует, чтобы при любом числе процессоров (строго говоря — процессорных ядер) в системе они все были одинаковые, каждый может быть заменен любым другим, и все они осуществляют доступ к одному и тому же массиву памяти.
    </p>
    <blockquote>* &mdash; pаньше многоядерный процессор на массовом рынке был мечтой практически неосуществимой, поэтому в тех отраслях, где требовалась высокая производительность в специфических задачах, использовались системы не многоядерные, а многопроцессорные. Вместо того, чтобы интегрировать N ядер в один чип — на системную плату устанавливали N разъёмов, и в них — N одноядерных процессоров. Условно, современный десктоп на N-ядерном процессоре, можно приравнять к N-процессорной системе. Впрочем, многопроцессорные системы есть и сейчас — для тех, кого не устраивает максимально возможное количество ядер в одном CPU. Так, например, если вам нужна 16-процессорная (16-ядерная) система — то ввиду отсутствия 16-ядерных x86-процессоров (пока, на 2009 г.…), вам придётся согласиться на 4-процессорную систему, в которой у каждого процессора будет по 4 ядра.</blockquote>
    <figure>
        <img src="https://i.imgur.com/EkJHrkA.png" alt="Motherboard" />
        <figcaption>
            4-процессорная системная плата, в каждый сокет которой можно установить<br>
            6-ядерный процессор. В результате мы получим 24-ядерную x86-систему.
        </figcaption>
    </figure>
    <p>
        Итак, наш главный вопрос: для чего всё это нужно? Каким образом за счёт увеличения количества ядер (процессоров) увеличивается быстродействие? Сразу расскажем, какой основной вопрос возникает при более детальном ознакомлении с многоядерными (многопроцессорными) системами: «Почему быстродействие увеличивается в разных случаях по-разному, а иногда не увеличивается вовсе?» Проще всего разъяснить это на примере простой и понятной аналогии с неким количеством работы, и неким количеством людей. Рассмотрим два самых распространённых варианта.
        <br><br>
        <strong>Вариант №1:</strong> несколько совершенно независимых друг от друга задач. Например, мы находимся в загородном доме, и нам необходимо наколоть дров и выкосить газон. Если у нас в распоряжении один человек — он будет вынужден сделать сначала одно дело, а потом другое, либо делать их параллельно, переключаясь между ними — но всё равно в один конкретный момент времени он будет занят чем-то одним. Если же есть два человека — то один может заняться колкой дров, а другой — косить газон. Заметьте: сами по себе задачи не стали выполняться быстрее — но мы экономим время за счёт того, что они выполняются параллельно. Продолжив аналогию, вы легко поймёте основной недостаток наращивания в данной ситуации количества людей  до бесконечности (а они у нас олицетворяют процессорные ядра или одноядерные процессоры): рано или поздно для ещё одного человека просто не найдётся работы. Или ресурсов: например, колоть дрова можно и вдвоём — но что делать, если у нас всего один топор?
        <br><br>
        <strong>Вариант №2:</strong> одна частично или полностью распараллеливаемая задача. Почти идеально распараллеливаемая задача (при условии, как уже было упомянуто выше, наличия должного количества ресурсов) — это та же колка дров, или, например, мытьё полов. Каждому в руки по швабре и ведру, каждому свой участок пола — и вперёд! Вы, правда, наверняка заметите, на основании банального житейского опыта, что ещё и задача должна быть соответствующего масштаба: хорошо мыть полы вчетвером в большом доме, но совершенно бессмысленно — в одной комнатушке. В случае с многоядерностью всё совершенно аналогично: быстро выполняемая задача, даже если она хорошо параллелится, вызывает давно известный эффект: согласование действий между выполняющими работу начинает занимать время, сопоставимое с временем выполнения самой работы каждым исполнителем. Русская пословица «у семи нянек дитя без глаза» примерно характеризует данную ситуацию.
        <br><br>
        Более сложный случай — например, варка борща. Конечно, хозяйка может поручить кому-то почистить овощи, кому-то нарезать, и т.д., но всё равно на некотором этапе у нас начнётся достаточно длительный процесс (собственно варки), в котором участие более чем одного человека совершенно не требуется. Это и есть частично распараллеливаемая задача: некоторые её этапы могут выполняться параллельно, а некоторые — нет. Совершенно очевидно, что даже если выделить на выполнение этой задачи двух людей, в 2 раза её выполнение не ускорится (а если четырёх — то в случае с борщом, четвёртый может оказаться в большинстве случаев лишним). И у многоядерных процессоров на частично распараллеливаемой задаче не все ядра могут задействоваться одновременно всё время. А значит, некоторые из них как минимум иногда будут простаивать.
        <br><br>
        Подытожим: добавление ещё одного ядра не всегда приводит к ускорению, а даже если и приводит — то не всегда настолько, сколько можно было бы ожидать в идеальном случае. Фактически, всё зависит от решаемых задач (используемых программ). Некоторые задачи параллелятся хорошо, некоторые — не очень, некоторые не параллелятся вообще. Почти идеально в большинстве случаев параллелятся две независимых задачи, но… для этого нужно, чтобы у вас достаточно часто возникала потребность решать несколько независимых задач одновременно! Говоря конкретней, двухъядерный процессор на программах обычного пользователя в среднем получит ускорение примерно раза в полтора, а 4-ядерный — примерно в два по сравнению с одноядерным. А вот при запуске «профессиональных» программ кратность ускорения часто почти равна числу ядер.
    </p>
    <h3>Число ядер и технология Hyper-Threading</h3>
    <p>Первое, что надо сказать о ядрах — в одном процессоре их бывает много. В вашем их, скорее всего, не менее двух, а вообще их может быть от 1 до 6 (скоро — и больше). Все ядра одинаковые, но кроме них в процессоре есть и обслуживающие их общие блоки — общий кэш, контроллер памяти и шины обмена с другими процессорами и/или с чипсетом. В новейших процессорах к этому списку скоро добавятся и специализированные ядра, например, для 3D-графики и декодирования видео. Когда говорят об устройстве ядер, то имеют ввиду каждое ядро многоядерного процессора (даже если говорится «ядро» в единственном числе).</p>
    <figure>
        <img src="https://i.imgur.com/wIUYFh3.png" alt="Scheme" />
        <figcaption>
            Многоядерная (многопроцессорная) система: благодаря наличию двух ядер (процессоров), можно<br> одновременно исполнять код двух программ
        </figcaption>
    </figure>
    <p>
        Как было сказано, у многоядерности есть ограничения по увеличению производительности. Когда задачи или их части выполняются параллельно, ядра конкурируют за доступ к общим блокам. Например, если запустить две задачи, сильно зависящие от пропускной способности памяти, и которым не хватит объёма кэша каждого ядра, то производительности общего для ядер кэша, а также контроллера памяти может быть недостаточно, чтобы насытить сразу два ядра. В результате они оба будут простаивать до половины времени — реальное увеличение скорости по сравнению с однопоточным исполнением может быть околонулевым. Противоположная ситуация, когда программы оптимизированы под многоядерные процессоры и не перегружают разделяемые ресурсы, выглядит примерно так: процессор исполняет столько потоков, сколько у него ядер, причём каждый поток в основном использует блоки своего ядра, а общение ядер между собой, а также с памятью достаточно редко, чтобы даже исполнение нескольких потоков не перегружало общие элементы процессора и не приводило к задержкам работы ядер. Подобрать по такому критерию несколько разных программ весьма сложно, а вот оптимизировать одну — удаётся куда чаще. Именно в таких случаях и удаётся получить то, что называется линейным ростом производительности от числа потоков (фактически — ядер): 2 ядра работают вдвое быстрее одного, 4 — вдвое быстрее двух, и т.д.. Всё вышесказанное касается и многопроцессорных систем, где число ядер каждого CPU надо умножить на число последних.
        <br><br>
        Дополнительную сложность вносит поддержка некоторыми процессорами технологии Hyper-Threading (гиперпоточности). Она позволяет одному ядру работать за два — хотя и не так эффективно, как реально существующая пара ядер, зато куда дешевле. При этом операционная система сообщает о процессоре с вдвое большим числом ядер, поскольку видит число ядер логических (по максимальному количеству одновременно запускаемых программ), а не физических (по числу реально выполняемых). Изменение производительности может быть от почти незаметного замедления до внушительного (20-50 %) ускорения и сильно зависит от набора исполняемых программ, а в среднем же ускорение равно 10-15%. К сожалению, чем лучше программа оптимизирована под настоящую многоядерность, тем меньше она выиграет от «виртуальной» за счёт Hyper-Threading.
    </p>
    <figure>
        <img src="https://i.imgur.com/WdYqoX9.png" alt="Scheme" />
        <figcaption>
            Процессор с поддержкой Hyper-Threading: на одном физическом ядре одновременно выполняется код двух приложений
        </figcaption>
    </figure>

    <h3>Различия между ядрами одной микроархитектуры</h3>
    <p>
        «Процессорное ядро» (как правило, для краткости его называют просто «ядро») — это конкретное воплощение (микро)архитектуры (т.е. архитектуры в «аппаратном» смысле), являющееся стандартом для целой серии процессоров. Например, K10 — это микроархитектура, которая лежит в основе многих сегодняшних процессоров AMD: Athlon II, Phenom, Phenom II, Opteron. Микроархитектура задаёт общие принципы: «средний» по длине конвейер, исполнение до трёх команд за такт, предсказание переходов и внеочередное исполнение, и прочие «глобальные» особенности. Ядро — более конкретное воплощение. Например, процессоры микроархитектуры К10 с двумя ядрами, без поддержки многопроцессорности и кэша L3, с шиной HyperTransport частотой в 2 ГГц — это более-менее полное описание ядра Regor для Athlon II.

        Можно сказать что «ядро» — это конкретное воплощение определённой микроархитектуры «в кремнии», обладающее (в отличие от самой микроархитектуры) набором строго обусловленных характеристик. Микроархитектура — аморфна, она описывает общие принципы построения процессора. Ядро — микроархитектура, «обросшая» всевозможными параметрами и характеристиками. Чрезвычайно редки случаи, когда процессоры сменяли микроархитектуру, сохраняя название. И, наоборот, практически любое наименование процессора хотя бы несколько раз за время своего существования «меняло» ядро. Например, общее название серии процессоров AMD — «Athlon 64» — это одна микроархитектура (K8), но целых 13 ядер — от Sledgehammer (2003 г.) до Huron (2009 г.). Разные ядра, построенные на одной микроархитектуре, могут иметь в том числе разное быстродействие.
    </p>

    <h3>Ревизии</h3>
    <p>Ревизия — одна из модификаций ядра, крайне незначительно отличающаяся от предыдущей, почему и не заслуживает звания «нового ядра». Как правило, из выпусков очередной ревизии производители процессоров не делают большого события, это происходит «в рабочем порядке». Так что даже если вы покупаете один и тот же процессор, с полностью аналогичным названием и характеристиками, но с интервалом где-то в полгода — вполне возможно, фактически он будет уже немного другой. Выпуск новой ревизии, как правило, связан с какими-то мелкими усовершенствованиями. Например, удалось чуть-чуть снизить энергопотребление, понизить напряжение питания, что-то оптимизировать, или была устранена пара мелких (иногда не очень…) ошибок. С точки зрения производительности была всего пара примеров, когда бы одна ревизия ядра отличалась от другой настолько существенно, чтобы об этом имело смысл говорить. Хотя чисто теоретически возможен и такой вариант — например, подвергся оптимизации один из блоков процессора, ответственный за исполнение нескольких команд. Подводя итог, можно сказать что «заморачиваться» ревизиями процессоров чаще всего не стоит: в очень редких случаях изменение ревизии вносит какие-то кардинальные изменения.</p>

    <h3>Частота работы ядра</h3>
    <p>
        Как правило, именно этот параметр в просторечии именуют «частотой процессора». Хотя в общем случае определение «частота работы ядра» всё же более корректно, так как совершенно не обязательно все составляющие CPU функционируют на той же частоте, что и ядро (наиболее частым примером обратного являлись старые «слотовые» x86 CPU — Intel Pentium II и Pentium III для Slot 1, AMD Athlon для Slot A — у них L2-кэш функционировал на 1/2, и даже иногда на 1/3 частоты работы ядра). Примерно также сегодня в большинстве процессоров работает кэш L3 — на своей отдельной частоте, меньшей, чем у каждого ядра. Ещё одним распространённым заблуждением является уверенность в том, что частота работы ядра однозначным образом определяет производительность. Это дважды не так.

        Во-первых, каждое конкретное процессорное ядро (в зависимости от того, как оно спроектировано, сколько содержит исполняющих блоков различных типов, и т.д. и т.п.) может исполнять разное число команд за один такт, частота же — это всего лишь количество таких тактов в секунду. Таким образом (приведённое далее сравнение, разумеется, очень сильно упрощено) процессор, ядро которого исполняет 3 инструкции за такт, может иметь на треть меньшую частоту, чем процессор, исполняющий 2 инструкции за такт — и при этом обладать полностью аналогичным быстродействием.

        Во-вторых, даже в рамках одного и того же ядра, увеличение частоты вовсе не всегда приводит к пропорциональному увеличению быстродействия. Здесь вам очень пригодятся знания, которые вы могли почерпнуть из раздела «Общие принципы взаимодействия процессора и ОЗУ». Дело в том, что скорость исполнения команд ядром процессора — это вовсе не единственный показатель, влияющий на скорость выполнения программы. Не менее важна скорость поступления команд и данных на CPU. Представим себе чисто теоретически такую систему: быстродействие процессора — 10'000 команд в секунду, скорость работы памяти — 1000 байт в секунду. Даже если принять, что одна команда занимает не более одного байта, а данных у нас нет совсем, с какой скоростью будет исполняться программа в такой системе? Не более 1000 команд в секунду, и производительность CPU тут совершенно ни при чём: мы будем ограничены не ей, а скоростью поступления команд в процессор. Таким образом, следует понимать: невозможно непрерывно наращивать одну только частоту ядра, не ускоряя одновременно подсистему памяти, так как в этом случае начиная с определённого этапа, увеличение частоты CPU перестанет сказываться на увеличении быстродействия системы в целом.

        Наконец, у компании Intel есть технология TurboBoost, особенность которой в том, что процессоры с её поддержкой вообще не имеют никакой конкретной частоты чего-либо. Смысл TurboBoost — увеличивать частоту загруженных ядер в зависимости от числа простаивающих, а также от температуры и энергопотребления всего процессора. В результате «нормальная» частота (написанная на коробке процессора или в прайс-листе) реально почти всегда будет превышена на 133-666 МГц (в мобильных процессорах серии Core i7 возможен разгон на 1333 МГц, если работает только одно ядро), причём всё время меняясь. Грубо говоря, можно сказать, что TurboBoost даст примерно +10% к скорости «за просто так».
    </p>

    <h3>Виртуализация</h3>
    <p>
        Виртуализация в вычислительной технике — это возможность запускать несколько операционных систем (и программы из-под каждой из них) так, что они будут работать будто бы на своих отдельных компьютерах (т.е. подразумевается виртуализация «железа» по отношению к програмам). Впервые она появилась аж в 60-е годы на мейнфреймах IBM и до недавнего времени была полезна лишь для программирования и высокопроизводительных сетевых серверов. Однако новая ОС фирмы Microsoft Windows 7 уже требует аппаратную поддержку виртуализации в процессоре, если предполагается запускать 32-битные программы, написанные для Windows XP и более ранних версий (т.е. читай — всегда). Так зачем нужна эта аппаратная поддержка, если ранее и программной справлялись?

        Аппаратная поддержка виртуализации в процессоре фактически означает наличие дополнительного поднабора команд, который позволяет инициировать, вызвать, завершать и переключать виртуальные ОС быстрее и с более надёжной изоляцией друг от друга (что важно для устойчивости и безопасности всей системы), чем программными средствами. Как обычно, оба главных производителя CPU стараются подчеркнуть преимущества своих реализаций, так что им даны разные имена: Intel Virtualization Technology (Intel VT) и AMD Virtualization (AMD-V). Причём между ними действительно есть небольшая разница, но, опять же, крайне незначительная и не приводящая к несовместимости. С точки зрения пользователя вердикт прост — поддержку виртуализации в процессоре лучше иметь, чем не иметь, т.к. даже если она не пригодится сейчас, то, возможно, пригодится через пару лет, а разница в стоимости у процессоров с и без неё почти незаметна. Более того — в новых CPU, виртуализацию поддерживают все модели, так что «хочешь, не хочешь»…
    </p>

    <h3>Особенности образования названий процессоров</h3>
    <p>
        Раньше, когда небо было голубее, пиво — вкуснее, а девушки — красивее (прим. ред.: мнение редакции не всегда совпадает с мнением авторов, особенно насчёт девушек), процессоры называли просто: имя производителя + название модельного ряда («линейки») + частота. Например: «AMD K6-2 450 MHz». В настоящее время оба основных производителя от этой традиции отошли и вместо частоты употребляют какие-то непонятные циферки, обозначающие невесть что. В первой версии статьи на этом месте было краткое объяснение того, что же эти циферки обозначают. Однако с тех пор (а прошло всего 3 года) оба основных производителя x86 CPU неоднократно меняли и дополняли эти правила, так что фактически уследить за ними в рамках даже регулярно обновляющегося цикла статей невозможно, да и не очень требуется. Есть способы лучше. Если вам нужно узнать основные характеристики какого-то процессора, проще всего просто набрать его полное имя в Гугле или Яндексе, и среди первой десятки результатов вы наверняка найдёте краткое описание его внутренностей. Если же требуется сравнить разные процессоры, названия которых вы не помните или не знаете, подойдёт Википедия: вот список всех процессоров AMD, а вот — процессоры Intel. Для любителей экзотики есть ещё процессоры VIA. Ссылки на детальные списки процессоров по линейкам (Celeron, Sempron, Core i7, Phenom, Nano и т.п.) см. в самом внизу страницы напротив слова Lists.

        Что касается общего положения, то у обоих основных производителей ситуация примерно такая (с многочисленными исключениями, разумеется). Сначала указывается название линейки процессоров. Оно говорит об общей направленности применения: бюджетные, основные (mainstream), дешёвые и экономные (для нетбуков), основные и экономные (для ноутбуков), просто быстрые и быстрые с поддержкой многопроцессорности (для рабочих станций и серверов). После указывается номер поколения этой линейки — не обязательно порядковый, но чем больше — тем «круче». Затем, на том месте, где ранее была частота — 2-4-значное число «рейтинга» производительности, обозначающее сразу несколько методов её увеличения:
    </p>
    <ul>
        <li>число физических ядер (логических больше, если у процессора есть технология типа Hyper-Threading);</li>
        <li>их частота (при наличии технологии Turbo Boost или ей подобной — максимальная частота продолжительной надёжной работы всех ядер с их полной загрузкой, максимальной допустимой температурой корпуса процессора и «нормальным» напряжением питания);</li>
        <li>полный объём всех кэшей;</li>
        <li>число контроллеров и шин памяти и чипсета;</li>
        <li>частота этих шин;</li>
        <li>возможность частотного разгона разными способами;</li>
        <li>наличие дополнительных специализированных блоков и шин;</li>
        <li>разные мелочи.</li>
    </ul>

    <p>
        Причём это число не является оценкой самой производительности, т.е. вы не только не сможете сказать, насколько модель 2300 быстрее модели 1200, но даже и какая из них быстрее в конкретной программе. Можно лишь утверждать, что с точки зрения производителя, модель 2300 сложнее в производстве, чем модель 1200 — у неё выше некоторые технические характеристики, больше ядер или кэша, и т.д. и т.п. При этом подразумевается, что раз уж модель с более высоким номером снабдили всеми этими «наворотами» — то она и работать будет быстрее (иначе зачем было снабжать?) Однако практика свидетельствует, что сбывается это предположение отнюдь не всегда.
        <br><br>
        Также иногда к «рейтингу» спереди или сзади добавляются 1-2 буквы для обозначения класса потребления энергии: для немобильных процессоров — просто «обычный» и «экономный», а для мобильных — более детальная градация.
    </p>
</body>
</html>